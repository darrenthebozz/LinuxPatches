diff -ruN linux-6.4.2-clean/arch/x86/mm/fault.c linux-6.4.2/arch/x86/mm/fault.c
--- linux-6.4.2-clean/arch/x86/mm/fault.c	2023-07-05 17:30:31.000000000 +0000
+++ linux-6.4.2/arch/x86/mm/fault.c	2023-07-10 20:24:37.820075857 +0000
@@ -1429,7 +1429,7 @@
 					 0, 0, ARCH_DEFAULT_PKEY);
 		return;
 	}
-
+#ifdef CONFIG_OOM
 	if (fault & VM_FAULT_OOM) {
 		/* Kernel mode? Handle exceptions or die: */
 		if (!user_mode(regs)) {
@@ -1446,6 +1446,7 @@
 		 */
 		pagefault_out_of_memory();
 	} else {
+#endif
 		if (fault & (VM_FAULT_SIGBUS|VM_FAULT_HWPOISON|
 			     VM_FAULT_HWPOISON_LARGE))
 			do_sigbus(regs, error_code, address, fault);
@@ -1453,7 +1454,9 @@
 			bad_area_nosemaphore(regs, error_code, address);
 		else
 			BUG();
+#ifdef CONFIG_OOM
 	}
+#endif
 }
 NOKPROBE_SYMBOL(do_user_addr_fault);
 
diff -ruN linux-6.4.2-clean/fs/proc/base.c linux-6.4.2/fs/proc/base.c
--- linux-6.4.2-clean/fs/proc/base.c	2023-07-05 17:30:31.000000000 +0000
+++ linux-6.4.2/fs/proc/base.c	2023-07-10 20:39:42.696744708 +0000
@@ -546,7 +546,7 @@
 };
 
 #endif
-
+#ifdef CONFIG_OOM
 static int proc_oom_score(struct seq_file *m, struct pid_namespace *ns,
 			  struct pid *pid, struct task_struct *task)
 {
@@ -567,7 +567,7 @@
 
 	return 0;
 }
-
+#endif
 struct limit_names {
 	const char *name;
 	const char *unit;
@@ -1034,7 +1034,7 @@
 	.llseek		= generic_file_llseek,
 	.release	= mem_release,
 };
-
+#ifdef CONFIG_OOM
 static ssize_t oom_adj_read(struct file *file, char __user *buf, size_t count,
 			    loff_t *ppos)
 {
@@ -1244,7 +1244,7 @@
 	.write		= oom_score_adj_write,
 	.llseek		= default_llseek,
 };
-
+#endif
 #ifdef CONFIG_AUDIT
 #define TMPBUFLEN 11
 static ssize_t proc_loginuid_read(struct file * file, char __user * buf,
@@ -3308,9 +3308,11 @@
 #ifdef CONFIG_PROC_CPU_RESCTRL
 	ONE("cpu_resctrl_groups", S_IRUGO, proc_resctrl_show),
 #endif
+#ifdef CONFIG_OOM
 	ONE("oom_score",  S_IRUGO, proc_oom_score),
 	REG("oom_adj",    S_IRUGO|S_IWUSR, proc_oom_adj_operations),
 	REG("oom_score_adj", S_IRUGO|S_IWUSR, proc_oom_score_adj_operations),
+#endif
 #ifdef CONFIG_AUDIT
 	REG("loginuid",   S_IWUSR|S_IRUGO, proc_loginuid_operations),
 	REG("sessionid",  S_IRUGO, proc_sessionid_operations),
@@ -3656,9 +3658,11 @@
 #ifdef CONFIG_PROC_CPU_RESCTRL
 	ONE("cpu_resctrl_groups", S_IRUGO, proc_resctrl_show),
 #endif
+#ifdef CONFIG_OOM
 	ONE("oom_score", S_IRUGO, proc_oom_score),
 	REG("oom_adj",   S_IRUGO|S_IWUSR, proc_oom_adj_operations),
 	REG("oom_score_adj", S_IRUGO|S_IWUSR, proc_oom_score_adj_operations),
+#endif
 #ifdef CONFIG_AUDIT
 	REG("loginuid",  S_IWUSR|S_IRUGO, proc_loginuid_operations),
 	REG("sessionid",  S_IRUGO, proc_sessionid_operations),
diff -ruN linux-6.4.2-clean/include/linux/oom.h linux-6.4.2/include/linux/oom.h
--- linux-6.4.2-clean/include/linux/oom.h	2023-07-05 17:30:31.000000000 +0000
+++ linux-6.4.2/include/linux/oom.h	2023-07-10 19:30:31.320068055 +0000
@@ -2,6 +2,7 @@
 #ifndef __INCLUDE_LINUX_OOM_H
 #define __INCLUDE_LINUX_OOM_H
 
+#ifdef CONFIG_OOM
 
 #include <linux/sched/signal.h>
 #include <linux/types.h>
@@ -112,4 +113,6 @@
 
 extern struct task_struct *find_lock_task_mm(struct task_struct *p);
 
+#endif /* CONFIG_OOM */
+
 #endif /* _INCLUDE_LINUX_OOM_H */
diff -ruN linux-6.4.2-clean/include/linux/sched/signal.h linux-6.4.2/include/linux/sched/signal.h
--- linux-6.4.2-clean/include/linux/sched/signal.h	2023-07-05 17:30:31.000000000 +0000
+++ linux-6.4.2/include/linux/sched/signal.h	2023-07-10 19:39:42.170069363 +0000
@@ -222,7 +222,7 @@
 	unsigned audit_tty;
 	struct tty_audit_buf *tty_audit_buf;
 #endif
-
+#ifdef CONFIG_OOM
 	/*
 	 * Thread is the potential origin of an oom condition; kill first on
 	 * oom
@@ -233,7 +233,7 @@
 					 * Only settable by CAP_SYS_RESOURCE. */
 	struct mm_struct *oom_mm;	/* recorded mm when the thread group got
 					 * killed by the oom killer */
-
+#endif
 	struct mutex cred_guard_mutex;	/* guard against foreign influences on
 					 * credential calculations
 					 * (notably. ptrace)
diff -ruN linux-6.4.2-clean/include/linux/sched.h linux-6.4.2/include/linux/sched.h
--- linux-6.4.2-clean/include/linux/sched.h	2023-07-05 17:30:31.000000000 +0000
+++ linux-6.4.2/include/linux/sched.h	2023-07-10 19:37:59.930069118 +0000
@@ -1430,10 +1430,11 @@
 #endif
 
 #ifdef CONFIG_MEMCG
+#ifdef CONFIG_OOM
 	struct mem_cgroup		*memcg_in_oom;
 	gfp_t				memcg_oom_gfp_mask;
 	int				memcg_oom_order;
-
+#endif
 	/* Number of pages to reclaim on returning to userland: */
 	unsigned int			memcg_nr_pages_over_high;
 
@@ -1462,7 +1463,7 @@
 	struct rcu_head			rcu;
 	refcount_t			rcu_users;
 	int				pagefault_disabled;
-#ifdef CONFIG_MMU
+#if defined(CONFIG_MMU) && defined(CONFIG_OOM)
 	struct task_struct		*oom_reaper_list;
 	struct timer_list		oom_reaper_timer;
 #endif
diff -ruN linux-6.4.2-clean/include/trace/events/oom.h linux-6.4.2/include/trace/events/oom.h
--- linux-6.4.2-clean/include/trace/events/oom.h	2023-07-05 17:30:31.000000000 +0000
+++ linux-6.4.2/include/trace/events/oom.h	2023-07-10 20:16:20.933407997 +0000
@@ -1,4 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
+#ifdef CONFIG_OOM
 #undef TRACE_SYSTEM
 #define TRACE_SYSTEM oom
 
@@ -193,3 +194,4 @@
 
 /* This part must be outside protection */
 #include <trace/define_trace.h>
+#endif
\ No newline at end of file
diff -ruN linux-6.4.2-clean/init/Kconfig linux-6.4.2/init/Kconfig
--- linux-6.4.2-clean/init/Kconfig	2023-07-05 17:30:31.000000000 +0000
+++ linux-6.4.2/init/Kconfig	2023-07-10 14:15:02.889004638 +0000
@@ -1452,7 +1452,6 @@
 menuconfig EXPERT
 	bool "Configure standard kernel features (expert users)"
 	# Unhide debug options, to make the on-by-default options visible
-	select DEBUG_KERNEL
 	help
 	  This option allows certain base kernel options and settings
 	  to be disabled or tweaked. This is for specialized
diff -ruN linux-6.4.2-clean/kernel/exit.c linux-6.4.2/kernel/exit.c
--- linux-6.4.2-clean/kernel/exit.c	2023-07-05 17:30:31.000000000 +0000
+++ linux-6.4.2/kernel/exit.c	2023-07-10 19:47:02.933403762 +0000
@@ -565,8 +565,10 @@
 	mmap_read_unlock(mm);
 	mm_update_next_owner(mm);
 	mmput(mm);
+#ifdef CONFIG_OOM
 	if (test_thread_flag(TIF_MEMDIE))
 		exit_oom_victim();
+#endif
 }
 
 static struct task_struct *find_alive_thread(struct task_struct *p)
diff -ruN linux-6.4.2-clean/kernel/fork.c linux-6.4.2/kernel/fork.c
--- linux-6.4.2-clean/kernel/fork.c	2023-07-05 17:30:31.000000000 +0000
+++ linux-6.4.2/kernel/fork.c	2023-07-10 19:45:53.496736924 +0000
@@ -934,7 +934,7 @@
 	free_mm(mm);
 }
 EXPORT_SYMBOL_GPL(__mmdrop);
-
+#ifdef CONFIG_OOM
 static void mmdrop_async_fn(struct work_struct *work)
 {
 	struct mm_struct *mm;
@@ -950,6 +950,7 @@
 		schedule_work(&mm->async_put_work);
 	}
 }
+#endif
 
 static inline void free_signal_struct(struct signal_struct *sig)
 {
@@ -959,8 +960,10 @@
 	 * __mmdrop is not safe to call from softirq context on x86 due to
 	 * pgd_dtor so postpone it to the async context
 	 */
+#ifdef CONFIG_OOM
 	if (sig->oom_mm)
 		mmdrop_async(sig->oom_mm);
+#endif
 	kmem_cache_free(signal_cachep, sig);
 }
 
@@ -1893,10 +1896,10 @@
 
 	tty_audit_fork(sig);
 	sched_autogroup_fork(sig);
-
+#ifdef CONFIG_OOM
 	sig->oom_score_adj = current->signal->oom_score_adj;
 	sig->oom_score_adj_min = current->signal->oom_score_adj_min;
-
+#endif
 	mutex_init(&sig->cred_guard_mutex);
 	init_rwsem(&sig->exec_update_lock);
 
@@ -2204,6 +2207,7 @@
 		free_task(tsk);
 }
 
+#ifdef CONFIG_OOM
 static void copy_oom_score_adj(u64 clone_flags, struct task_struct *tsk)
 {
 	/* Skip if kernel thread */
@@ -2223,6 +2227,8 @@
 	mutex_unlock(&oom_adj_mutex);
 }
 
+#endif
+
 #ifdef CONFIG_RV
 static void rv_task_fork(struct task_struct *p)
 {
@@ -2735,9 +2741,9 @@
 	trace_task_newtask(p, clone_flags);
 	uprobe_copy_process(p, clone_flags);
 	user_events_fork(p, clone_flags);
-
+#ifdef CONFIG_OOM
 	copy_oom_score_adj(clone_flags, p);
-
+#endif
 	return p;
 
 bad_fork_cancel_cgroup:
diff -ruN linux-6.4.2-clean/mm/Kconfig linux-6.4.2/mm/Kconfig
--- linux-6.4.2-clean/mm/Kconfig	2023-07-05 17:30:31.000000000 +0000
+++ linux-6.4.2/mm/Kconfig	2023-07-10 17:53:25.512528646 +0000
@@ -938,6 +938,13 @@
 	  lifetime of the system until these kthreads finish the
 	  initialisation.
 
+config OOM
+	bool "Enable OOM (Out Of Memory) Killer"
+	default y
+	help
+	  OOM Killer tries to recover the system from out of memory cases by
+	  choosing which task lives or dies, freeing up memory.
+
 config PAGE_IDLE_FLAG
 	bool
 	select PAGE_EXTENSION if !64BIT
diff -ruN linux-6.4.2-clean/mm/Makefile linux-6.4.2/mm/Makefile
--- linux-6.4.2-clean/mm/Makefile	2023-07-05 17:30:31.000000000 +0000
+++ linux-6.4.2/mm/Makefile	2023-07-10 17:57:15.449204494 +0000
@@ -45,8 +45,7 @@
 ifdef CONFIG_CROSS_MEMORY_ATTACH
 mmu-$(CONFIG_MMU)	+= process_vm_access.o
 endif
-
-obj-y			:= filemap.o mempool.o oom_kill.o fadvise.o \
+obj-y			:= filemap.o mempool.o fadvise.o \
 			   maccess.o page-writeback.o folio-compat.o \
 			   readahead.o swap.o truncate.o vmscan.o shmem.o \
 			   util.o mmzone.o vmstat.o backing-dev.o \
@@ -55,6 +54,10 @@
 			   interval_tree.o list_lru.o workingset.o \
 			   debug.o gup.o mmap_lock.o $(mmu-y)
 
+ifdef CONFIG_OOM
+	obj-y += oom_kill.o
+endif
+
 # Give 'page_alloc' its own module-parameter namespace
 page-alloc-y := page_alloc.o
 page-alloc-$(CONFIG_SHUFFLE_PAGE_ALLOCATOR) += shuffle.o
diff -ruN linux-6.4.2-clean/mm/memory.c linux-6.4.2/mm/memory.c
--- linux-6.4.2-clean/mm/memory.c	2023-07-05 17:30:31.000000000 +0000
+++ linux-6.4.2/mm/memory.c	2023-07-10 19:51:06.550071020 +0000
@@ -4068,7 +4068,9 @@
 			update_mmu_tlb(vma, vmf->address, vmf->pte);
 			goto unlock;
 		}
+#ifdef CONFIG_OOM
 		ret = check_stable_address_space(vma->vm_mm);
+#endif
 		if (ret)
 			goto unlock;
 		/* Deliver the page fault to userland, check inside PT lock */
@@ -4108,8 +4110,9 @@
 		update_mmu_tlb(vma, vmf->address, vmf->pte);
 		goto release;
 	}
-
+#ifdef CONFIG_OOM
 	ret = check_stable_address_space(vma->vm_mm);
+#endif
 	if (ret)
 		goto release;
 
@@ -4361,12 +4364,13 @@
 	 * check even for read faults because we might have lost our CoWed
 	 * page
 	 */
+#ifdef CONFIG_OOM
 	if (!(vma->vm_flags & VM_SHARED)) {
 		ret = check_stable_address_space(vma->vm_mm);
 		if (ret)
 			return ret;
 	}
-
+#endif
 	if (pmd_none(*vmf->pmd)) {
 		if (PageTransCompound(page)) {
 			ret = do_set_pmd(vmf, page);
diff -ruN linux-6.4.2-clean/mm/page_alloc.c linux-6.4.2/mm/page_alloc.c
--- linux-6.4.2-clean/mm/page_alloc.c	2023-07-05 17:30:31.000000000 +0000
+++ linux-6.4.2/mm/page_alloc.c	2023-07-10 20:19:55.230075181 +0000
@@ -2912,9 +2912,10 @@
 			 * failing a high-order atomic allocation in the
 			 * future.
 			 */
+#ifdef CONFIG_OOM
 			if (!page && (alloc_flags & ALLOC_OOM))
 				page = __rmqueue_smallest(zone, order, MIGRATE_HIGHATOMIC);
-
+#endif
 			if (!page) {
 				spin_unlock_irqrestore(&zone->lock, flags);
 				return NULL;
@@ -3204,8 +3205,10 @@
 		 * the exit path shortly and free memory. Any allocation it
 		 * makes during the free path will be small and short-lived.
 		 */
+#ifdef CONFIG_OOM
 		if (alloc_flags & ALLOC_OOM)
 			min -= min / 2;
+#endif
 	}
 
 	/*
@@ -3239,10 +3242,13 @@
 			return true;
 		}
 #endif
+
+#ifdef CONFIG_OOM
 		if ((alloc_flags & (ALLOC_HIGHATOMIC|ALLOC_OOM)) &&
 		    !free_area_empty(area, MIGRATE_HIGHATOMIC)) {
 			return true;
 		}
+#endif
 	}
 	return false;
 }
@@ -3541,10 +3547,12 @@
 	 * contexts that are allowed to allocate outside current's set
 	 * of allowed nodes.
 	 */
+#ifdef CONFIG_OOM
 	if (!(gfp_mask & __GFP_NOMEMALLOC))
 		if (tsk_is_oom_victim(current) ||
 		    (current->flags & (PF_MEMALLOC | PF_EXITING)))
 			filter &= ~SHOW_MEM_FILTER_NODES;
+#endif
 	if (!in_task() || !(gfp_mask & __GFP_DIRECT_RECLAIM))
 		filter &= ~SHOW_MEM_FILTER_NODES;
 
@@ -3595,7 +3603,7 @@
 
 	return page;
 }
-
+#ifdef CONFIG_OOM
 static inline struct page *
 __alloc_pages_may_oom(gfp_t gfp_mask, unsigned int order,
 	const struct alloc_context *ac, unsigned long *did_some_progress)
@@ -3682,7 +3690,7 @@
 	mutex_unlock(&oom_lock);
 	return page;
 }
-
+#endif
 /*
  * Maximum number of compaction retries with a progress before OOM
  * killer is consider as the only way to move forward.
@@ -4079,7 +4087,7 @@
 
 	return alloc_flags;
 }
-
+#ifdef CONFIG_OOM
 static bool oom_reserves_allowed(struct task_struct *tsk)
 {
 	if (!tsk_is_oom_victim(tsk))
@@ -4094,7 +4102,7 @@
 
 	return true;
 }
-
+#endif
 /*
  * Distinguish requests which really need access to full memory
  * reserves from oom victims which can live with a portion of it
@@ -4110,8 +4118,10 @@
 	if (!in_interrupt()) {
 		if (current->flags & PF_MEMALLOC)
 			return ALLOC_NO_WATERMARKS;
+#ifdef CONFIG_OOM
 		else if (oom_reserves_allowed(current))
 			return ALLOC_OOM;
+#endif
 	}
 
 	return 0;
@@ -4182,8 +4192,10 @@
 		 */
 		wmark = __zone_watermark_ok(zone, order, min_wmark,
 				ac->highest_zoneidx, alloc_flags, available);
+#ifdef CONFIG_OOM
 		trace_reclaim_retry_zone(z, order, reclaimable,
 				available, min_wmark, *no_progress_loops, wmark);
+#endif
 		if (wmark) {
 			ret = true;
 			break;
@@ -4439,7 +4451,7 @@
 	if (check_retry_cpuset(cpuset_mems_cookie, ac) ||
 	    check_retry_zonelist(zonelist_iter_cookie))
 		goto restart;
-
+#ifdef CONFIG_OOM
 	/* Reclaim has failed us, start killing things */
 	page = __alloc_pages_may_oom(gfp_mask, order, ac, &did_some_progress);
 	if (page)
@@ -4450,7 +4462,7 @@
 	    (alloc_flags & ALLOC_OOM ||
 	     (gfp_mask & __GFP_NOMEMALLOC)))
 		goto nopage;
-
+#endif
 	/* Retry as long as the OOM killer is making progress */
 	if (did_some_progress) {
 		no_progress_loops = 0;
